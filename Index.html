<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1.0">
  <title>顔トラッキング＋スタンプ</title>
  <style>
    html, body {
      margin: 0; padding: 0;
      overflow: hidden;
      width: 100vw; height: 100vh;
    }
    #video, #overlay {
      position: absolute;
      top: 0; left: 0;
      width: 100%; height: 100%;
      object-fit: cover;
    }
    /* overlay は透過だけ使うので、クリックなどを邪魔しない */
    #overlay { pointer-events: none; }
  </style>
</head>
<body>

  <!-- カメラ映像 -->
  <video id="video" autoplay playsinline></video>
  <!-- ここにスタンプを描画 -->
  <canvas id="overlay"></canvas>

  <script type="module">
  import { FaceMesh } from 'https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js';
  import { Camera }   from 'https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js';

  const video   = document.getElementById('video');
  const overlay = document.getElementById('overlay');
  const octx    = overlay.getContext('2d');

  // ここに置きたいPNGを用意（例：サングラス）
  const glasses = new Image();
  glasses.src = 'glasses.png';  // 同じフォルダに置いてください

  // FaceMesh 初期化
  const faceMesh = new FaceMesh({
    locateFile: file => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`
  });
  faceMesh.setOptions({
    maxNumFaces: 1,
    minDetectionConfidence: 0.5,
    minTrackingConfidence: 0.5
  });

  // 顔検出結果が来たら overlay にスタンプを描画
  faceMesh.onResults(results => {
    // overlay canvas の大きさを video と合わせる
    overlay.width  = video.videoWidth;
    overlay.height = video.videoHeight;
    octx.clearRect(0, 0, overlay.width, overlay.height);

    if (results.multiFaceLandmarks && glasses.complete) {
      const lm = results.multiFaceLandmarks[0];
      // ランドマーク33 (左目近く)、263 (右目近く) を使う例
      const L = lm[33], R = lm[263];
      const lx = L.x * overlay.width,  ly = L.y * overlay.height;
      const rx = R.x * overlay.width,  ry = R.y * overlay.height;
      
      // 眼間の距離をベースに幅を決定
      const dist = Math.hypot(rx - lx, ry - ly);
      const w = dist * 2.5;                    // サングラス幅
      const h = w * (glasses.height / glasses.width);
      
      // 中心点を求めて位置調整
      const cx = (lx + rx) / 2 - w / 2;
      const cy = (ly + ry) / 2 - h / 2 - (0.1 * h);

      octx.drawImage(glasses, cx, cy, w, h);
    }
  });

  // カメラ起動＋MediaPipe 連携
  const camera = new Camera(video, {
    onFrame: async () => {
      await faceMesh.send({ image: video });
    },
    width: 640,
    height: 480,
    facingMode: 'environment'  // 'user' にするとインカメラ
  });
  camera.start();
  </script>

</body>
</html>
