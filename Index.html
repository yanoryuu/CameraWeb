<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, viewport-fit=cover">
  <title>顔トラッキング＋スタンプ</title>
  <style>
    html, body {
      margin: 0; padding: 0;
      width: 100vw; height: 100vh;
      overflow: hidden;
      background: #000;
    }
    /* ビデオとオーバーレイを重ねる */
    #video, #overlay {
      position: absolute;
      top: 0; left: 0;
      width: 100%; height: 100%;
      object-fit: cover;
    }
    /* overlay はクリック透過 */
    #overlay {
      pointer-events: none;
    }
  </style>
</head>
<body>

  <!-- カメラ映像 -->
  <video id="video" autoplay playsinline></video>
  <!-- 顔上にスタンプを描画 -->
  <canvas id="overlay"></canvas>

  <script type="module">
    // MediaPipe FaceMesh と CameraUtils を CDN から読み込む
    import { FaceMesh } from 'https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js';
    import { Camera }   from 'https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js';

    const video   = document.getElementById('video');
    const overlay = document.getElementById('overlay');
    const ctx     = overlay.getContext('2d');

    // 透過PNG スタンプ画像（同フォルダに glasses.png を配置）
    const stamp = new Image();
    stamp.src = 'glasses.png';

    // FaceMesh の初期設定
    const faceMesh = new FaceMesh({
      locateFile: file => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`
    });
    faceMesh.setOptions({
      maxNumFaces: 1,
      minDetectionConfidence: 0.5,
      minTrackingConfidence: 0.5
    });

    // 検出結果で overlay にスタンプを描画
    faceMesh.onResults(results => {
      // canvas サイズを video と合わせる
      overlay.width  = video.videoWidth;
      overlay.height = video.videoHeight;
      ctx.clearRect(0, 0, overlay.width, overlay.height);

      if (results.multiFaceLandmarks && stamp.complete) {
        const lm = results.multiFaceLandmarks[0];

        // 例：ランドマーク33（左目内側）と263（右目内側）を取得
        const L = lm[33], R = lm[263];
        const lx = L.x * overlay.width,  ly = L.y * overlay.height;
        const rx = R.x * overlay.width,  ry = R.y * overlay.height;

        // 目間距離を元にスタンプサイズを決定
        const dist = Math.hypot(rx - lx, ry - ly);
        const w = dist * 2.5;  // 幅を調整
        const h = w * (stamp.height / stamp.width);

        // スタンプの描画位置（目位置の中央、やや上にオフセット）
        const cx = (lx + rx) / 2 - w / 2;
        const cy = (ly + ry) / 2 - h / 2 - (0.1 * h);

        ctx.drawImage(stamp, cx, cy, w, h);
      }
    });

    // カメラ起動と FaceMesh へのフレーム送信
    const camera = new Camera(video, {
      onFrame: async () => {
        await faceMesh.send({ image: video });
      },
      width: 640,
      height: 480,
      facingMode: 'environment'  // 背面カメラ。インカメラは 'user'
    });
    camera.start();
  </script>

</body>
</html>
