<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, viewport-fit=cover">
  <title>顔トラッキングテスト</title>

  <!-- MediaPipe FaceMesh と CameraUtils をグローバル読み込み -->
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh@0.3/face_mesh.js"
          crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils@0.3/camera_utils.js"
          crossorigin="anonymous"></script>

  <style>
    html, body {
      margin: 0; padding: 0;
      width: 100vw; height: 100vh;
      overflow: hidden;
      background: #000;
      display: flex; justify-content: center; align-items: center;
    }
    video, canvas {
      position: absolute;
      top: 0; left: 0;
      width: 100%; height: 100%;
      object-fit: cover;
    }
    canvas { pointer-events: none; }
  </style>
</head>
<body>

  <video id="video" autoplay playsinline muted></video>
  <canvas id="overlay"></canvas>

  <script>
    // 要素取得
    const video   = document.getElementById('video');
    const overlay = document.getElementById('overlay');
    const ctx     = overlay.getContext('2d');

    // FaceMesh 初期化
    const faceMesh = new FaceMesh({
      locateFile: f => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh@0.3/${f}`
    });
    faceMesh.setOptions({
      maxNumFaces: 1,
      minDetectionConfidence: 0.5,
      minTrackingConfidence: 0.5
    });

    // 結果受け取り時にランドマークを描画
    faceMesh.onResults(results => {
      // canvas サイズを video に合わせる
      overlay.width  = video.videoWidth;
      overlay.height = video.videoHeight;
      ctx.clearRect(0, 0, overlay.width, overlay.height);

      if (!results.multiFaceLandmarks) return;

      for (const landmarks of results.multiFaceLandmarks) {
        ctx.fillStyle = 'cyan';
        for (const point of landmarks) {
          const x = point.x * overlay.width;
          const y = point.y * overlay.height;
          ctx.beginPath();
          ctx.arc(x, y, 2, 0, 2 * Math.PI);
          ctx.fill();
        }
      }
    });

    // カメラ起動とフレーム送信
    const camera = new Camera(video, {
      onFrame: async () => {
        await faceMesh.send({ image: video });
      },
      width: 640,
      height: 480,
      facingMode: 'environment'
    });
    camera.start();
  </script>

</body>
</html>
